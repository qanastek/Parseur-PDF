<article>
<preamble>
Alexandrov_2015_A_Modified_Tripartite_Model_for_Document_Representation_in_Internet_Sociology
</preamble>
<titre>
A Modified Tripartite Model for Document
</titre>
<auteur>
[u'Representation in Internet Sociology']
</auteur>
<abstract>
 Seven years ago Peter Mika (Yahoo! Research) proposed a tripartite model of actors, concepts and instances for document representation in the study of social networks. We propose a modified model, where instead of document authors we consider textual mentions of persons and institutions as actors. This representation proves to be more appropriate for the solution of a range of Internet Sociology tasks. In the paper we describe experiments with the modified model and provide some background on the tools that can be used to build it. The model is tested on the experimental corpora of Russian news (educational domain). The research reflects the pilot study findings. 
</abstract>
<biblio>
1. Alexandrov, M.: Development of general methodology for analysis of public opinion
of Internet-community and its application to given topics (authority, economy,
corruption, etc.) on the basis of Data/Text Mining tools. Report on State project
84, RPANEPA [rus] (2013)
2. Alexandrov, M., Beresneva, D., Makarov, A.: Dynamic vocabularies as a tool for
studying social processes. In: Proceedings of the 6th International Conference on
Intelligent Information and Engineering Systems, ITHEA Publishing, vol. 27, pp.
3. Alexandrov, M., Danilova, V., Koshulko, A., Tejada, J.: Models for opinion classification of blogs taken from Peruvian Facebook. In: Proceedings of the 4th International Conference on Inductive Modeling (ICIM-2013), Kyiv, Ukraine Publishing
House ITRC-NASU (Ukraine) &amp; Czech Technical University pp. 241&#8211;246 (2013)
4. Alexandrov, M., Gelbukh, A., Rosso, P.: An approach to clustering abstracts.
In: Montoyo, A., Mun&#771;oz, R., Me&#769;tais, E. (eds.) NLDB 2005. LNCS, vol. 3513,
pp. 275&#8211;285. Springer, Heidelberg (2005)
5. Alexandrov, M., Gelbukh, A., Makagonov, P.: Evaluation of thematic structure
of multidisciplinary documents and document flows. In: Proceedings of the 11th
International DEXA Workshop (Database and Expert System Applications), pp.
6. Baeza-Yates, R., Ribero-Neto, B.: Modern Information Retrieval. Addison Wesley,
7. Bishop, C.: Pattern Recognition and Machine Learning. Springer, Berkeley (2006)
8. Danilova, V., Alexandrov, M., Blanco, X.: A survey of multilingual event extraction
from text. In: Me&#769;tais, E., Roche, M., Teisseire, M. (eds.) NLDB 2014. LNCS,
vol. 8455, pp. 85&#8211;88. Springer, Heidelberg (2014)
9. Danilova V., Popova S.: Socio-political event extraction using a rule-based approach. In: Meersman, R., Panetto, H., Mishra, A., Valencia-Garcia, R., Soares, A.L.,
Ciuciu, I., Ferri, F., Weichhart, G., Moser, T., Bezzi, M., Chan, H. (eds.) Proceedings
of the 13th International Conference on Ontologies, DataBases and Applications of
Semantics (ODBASE&#8217;2014), vol 8842, pp. 537&#8211;546, Springer (2014)
10. Gelbukh, A., Sidorov, G., Guzman-Arenas, A.: Use of a weighted topic hierarchy for
document classification. In: Matous&#780;ek, V., et al. (eds.) TSD 1999. LNCS (LNAI),
vol. 1692, pp. 133&#8211;138. Springer, Heidelberg (1999)
11. Manning, C., Raghavan, P., Schutze, H.: Introduction to Information Retrieval.
Cambridge University Press, Cambridge (2008)
12. Eissen, S.M., Stein, B.: Analysis of clustering algorithms for web-based search.
In: Karagiannis, D., Reimer, U. (eds.) PAKM 2002. LNCS (LNAI), vol. 2569, pp.
168&#8211;178. Springer, Heidelberg (2002)
13. Mika, P.: Ontologies are us: a unified model of social networks and semantics. J.
Web Semant. Sci. Serv. Agents World Wide Web 5(1), 5&#8211;15 (2007)
14. Stein, B., Niggemann, O.: On the nature of structure and its identification. In:
Widmayer, P., Neyer, G., Eidenbenz, S. (eds.) WG 1999. LNCS, vol. 1665, p. 122.
Springer, Heidelberg (1999)

</biblio>

</article>
<article>
<preamble>
Doyle_2005_Automatic_Categorization_of_Author_Gender
</preamble>
<titre>
Automatic Categorization of Author Gender
</titre>
<auteur>
[u'via N-Gram Analysis']
</auteur>
<abstract>
 We present a method for automatic categorization of author gender via n-gram analysis. Using a corpus of British student essays, experiments using character-level, wordlevel, and part-of-speech n-grams are performed. The peak accuracy for all methods is roughly equal, reaching a maximum of 81%. These results are on par with other, established techniques, while retaining the simplicity and ease-of-generalization inherent in n-gram techniques.
</abstract>
<biblio>
A. Aizawa. 2001. Linguistic techniques to improve
the performance of automatic text categorization. In Proceedings 6th NLP Pac. Rim Symp.
Shlomo Argamon, Moshe Koppel, Jonathan Fine,
and Anat Rachel Shimoni. 2003. Gender, genre,
and writing style in formal written texts. Text,
W. Cavnar and J. Trenkle. 1994. N-gram-based
text categorization. In Proceedings SDAIR-94.
Shyamala Doraisamy and Stefan Ruger. 2003.
Robust polyphonic music retrieval with ngrams. Journal of Intelligent Information Systems, 21(1):53&#8211;70, July.
N. Fakotakis E. Stamatatos and G. Kokkinakis.
2000. Automatic text categorization in terms
of genre and author. Computational Linguistics,
M. Ephratt. 1997. Authorship attribution - the
case of lexical innovations. In Proc. ACH-ALLC97.
Aidan Finn and Nicholas Kushmerick.
Learning to classify documents according to
genre. In IJCAI-03 Workshop on Computational
Approaches to Style Analysis and Synthesis.
Stephen M. Harding, W. Bruce Croft, and C. Weir.
1997. Probabilistic retrieval of ocr degraded text
using n-grams. Probabilistic Retrieval of OCR
Degraded Text Using N-Grams, 1324:345&#8211;359.
M. Mahoui I. Witten, Z. Bray and W. Teahan.
1999. Text mining: A new frontier for lossless
compression. In Proceedings of the IEEE Data
Compression Conference (DCC).
Vlado Keselj, Fuchun Peng, Nick Cercone, and
Calvin Thomas. 2003. N-gram-based author
profiles for authorship attribution. Proceedings
of the Conference Pacific Association for Computational Linguistics PACLING&#8217;03, August.
D. Khmelev and W. Teahan. 2003. A repetition
based measure for verification of text collections
and for text categorization. In SIGIR&#8217;2003,
Toronto, Canada.
Moshe Koppel, Shlomo Argamon, and Anat Rachel
Shimoni. 2002. Automatically categorizing written texts by author gender. Literary and Linguistic Computing, 17(4):401&#8211;412.
Hilary Nesi, Gerard Sharpling, and Lisa
Ganobcsik-Williams. 2004. Student papers
across the curriculum: Designing and developing a corpus of british student writing.
Computers and Composition, 21(4):439&#8211;450.
R. Rickman and P. Rosin. 1996. Content-based
image retrieval using colour n-grams. IEEE Colloquium on Intelligent Image Databases, pages
S. Scott and S. Matwin. 1999. Feature engineering
for text classification. In Proceedings ICML-99.
E. Stamatatos, N. Fakotakis, and G. Kokkinakis.
2001. Computer-based authorship attribution
without lexical measures. Computers and the
Humanities, 35:193&#8211;214.
J. Cleary T. Bell and I. Witten. 1990. Text Compression. Prentice Hall.
Ying Zhao and Justin Zobel. 2005. Effective
and scalable authorship attribution using function words. The 2nd Asia Information Retrieval

</biblio>

</article>
<article>
<preamble>
Furui_2004_Speech-to-text_and_speech-to-speech_summarization_of_spontaneous_speech
</preamble>
<titre>
IEEE TRANSACTIONS ON SPEECH AND AUDIO PROCESSING, VOL. 12, NO. 4, JULY 2004
</titre>
<auteur>
[u'']
</auteur>
<abstract>
This paper presents techniques for speech-to-text and speech-to-speech automatic summarization based on speech unit extraction and concatenation. For the former case, a two-stage summarization method consisting of important sentence extraction and word-based sentence compaction is investigated. Sentence and word units which maximize the weighted sum of linguistic likelihood, amount of information, confidence measure, and grammatical likelihood of concatenated units are extracted from the speech recognition results and concatenated for producing summaries. For the latter case, sentences, words, and between-filler units are investigated as units to be extracted from original speech. These methods are applied to the summarization of unrestricted-domain spontaneous presentations and evaluated by objective and subjective measures. It was confirmed that proposed methods are effective in spontaneous speech summarization. Index Terms&#8212;Presentation, speech recognition, speech summarization, speech-to-speech, speech-to-text, spontaneous speech.
</abstract>
<biblio>
[1] S. Furui, K. Iwano, C. Hori, T. Shinozaki, Y. Saito, and S. Tamura,
&#8220;Ubiquitous speech processing,&#8221; in Proc. ICASSP2001, vol. 1, Salt Lake
City, UT, 2001, pp. 13&#8211;16.
[2] S. Furui, &#8220;Recent advances in spontaneous speech recognition and understanding,&#8221; in Proc. ISCA-IEEE Workshop on Spontaneous Speech
Processing and Recognition, Tokyo, Japan, 2003.
[3] I. Mani and M. T. Maybury, Eds., Advances in Automatic Text Summarization. Cambridge, MA: MIT Press, 1999.
[4] J. Alexandersson and P. Poller, &#8220;Toward multilingual protocol generation for spontaneous dialogues,&#8221; in Proc. INLG-98, Niagara-on-the-lake,
[5] K. Zechner and A. Waibel, &#8220;Minimizing word error rate in textual summaries of spoken language,&#8221; in Proc. NAACL, Seattle, WA, 2000.
[6] J. S. Garofolo, E. M. Voorhees, C. G. P. Auzanne, and V. M. Stanford,
&#8220;Spoken document retrieval: 1998 evaluation and investigation of new
metrics,&#8221; in Proc. ESCA Workshop: Accessing Information in Spoken
Audio, Cambridge, MA, 1999, pp. 1&#8211;7.
[7] R. Valenza, T. Robinson, M. Hickey, and R. Tucker, &#8220;Summarization of
spoken audio through information extraction,&#8221; in Proc. ISCA Workshop
on Accessing Information in Spoken Audio, Cambridge, MA, 1999, pp.
[8] K. Koumpis and S. Renals, &#8220;Transcription and summarization of voicemail speech,&#8221; in Proc. ICSLP 2000, 2000, pp. 688&#8211;691.
[9] K. Maekawa, H. Koiso, S. Furui, and H. Isahara, &#8220;Spontaneous speech
corpus of Japanese,&#8221; in Proc. LREC2000, Athens, Greece, 2000, pp.
[10] T. Kikuchi, S. Furui, and C. Hori, &#8220;Two-stage automatic speech summarization by sentence extraction and compaction,&#8221; in Proc. ISCA-IEEE
Workshop on Spontaneous Speech Processing and Recognition, Tokyo,
[11] C. Hori and S. Furui, &#8220;Advances in automatic speech summarization,&#8221;
in Proc. Eurospeech 2001, 2001, pp. 1771&#8211;1774.
[12] C. Hori, S. Furui, R. Malkin, H. Yu, and A. Waibel, &#8220;A statistical approach to automatic speech summarization,&#8221; EURASIP J. Appl. Signal
Processing, pp. 128&#8211;139, 2003.
[13] K. Knight and D. Marcu, &#8220;Summarization beyond sentence extraction:
A probabilistic approach to sentence compression,&#8221; Artific. Intell., vol.
139, pp. 91&#8211;107, 2002.
[14] H. Daume III and D. Marcu, &#8220;A noisy-channel model for document compression,&#8221; in Proc. ACL-2002, Philadelphia, PA, 2002, pp. 449&#8211;456.
[15] C.-Y. Lin and E. Hovy, &#8220;From single to multi-document summarization:
A prototype system and its evaluation,&#8221; in Proc. ACL-2002, Philadelphia, PA, 2002, pp. 457&#8211;464.
[16] M. Hirohata, Y. Shinnaka, and S. Furui, &#8220;A study on important sentence
extraction methods using SVD for automatic speech summarization,&#8221;
in Proc. Acoustical Society of Japan Autumn Meeting, Nagoya, Japan,
[17] K. Zechner, &#8220;Spoken language condensation in the 21st Century,&#8221; in
Proc. Eurospeech, Geneva, Switzerland, 2003, pp. 1989&#8211;1992.
408
IEEE TRANSACTIONS ON SPEECH AND AUDIO PROCESSING, VOL. 12, NO. 4, JULY 2004
Sadaoki Furui (F&#8217;93) is a Professor at the Department of Computer Science, Tokyo Institute
of Technology, Tokyo, Japan. He is engaged in a
wide range of research on speech analysis, speech
recognition, speaker recognition, speech synthesis,
and multimodal human-computer interaction and
has authored or coauthored over 350 published
articles. From 1978 to 1979, he served on staff at
the Acoustics Research Department of Bell Laboratories, Murray Hill, NJ, as a Visiting Researcher,
working on speaker verification. He is the author of
Digital Speech Processing, Synthesis, and Recognition (New York: Marcel
Dekker, 1989; revised, 2000), Digital Speech Processing (Tokai, Japan:
Tokai Univ. Press, 1985), Acoustics and Speech Processing (Tokyo, Japan:
Kindai-Kagaku-Sha, 1992) in Japanese, and Speech Information Processing
(Tokyo, Japan: Morikita, 1998). He edited (with M. M. Sondhi) Advances in
Speech Signal Processing (New York: Marcel Dekker, 1992). He has translated
into Japanese Fundamentals of Speech Recognition (Tokyo, Japan: NTT
Advanced Technology, 1995), authored by L. R. Rabiner and B.-H. Juang,
and Vector Quantization and Signal Compression (Tokyo, Japan: Corona-sha,
1998), authored by A. Gersho and R. M. Gray.
Dr. Furui is a Fellow of the Acoustical Society of America and the Institute of
Electronics, Information and Communication Engineers of Japan (IEICE). He
is President of the Acoustical Society of Japan (ASJ), the International Speech
Communication Association (ISCA), and the Permanent Council for International Conferences on Spoken Language Processing (PC-ICSLP). He is a Board
of Governor of the IEEE Signal Processing Society (SPS) and in 1993, he served
as an IEEE SPS Distinguished Lecturer. He has served on the IEEE Technical
Committee on Speech and MMSP and on numerous IEEE Conference organizing committees. He is Editor-in-Chief of the Transactions of the IEICE. He
is also an Editorial Board member of Speech Communication, the Journal of
Computer Speech and Language, and the Journal of Digital Signal Processing.
He has received numerous awards, including: the Yonezawa Prize and the Paper
Awards from the IEICE (1975, 1988, 1993, and 2003); the Sato Paper Award
from the ASJ (1985 and 1987); the Senior Award from the IEEE Acoustics,
Speech, and Signal Processing Society (1989); the Achievement Award from
the Minister of Science and Technology of Japan (1989); the Technical Achievement Award and the Book Award from the IEICE (1990 and 2003); the Mira Paul
Memorial Award from the AFECT of India (2001).
Tomonori Kikuchi received the B. E. and M. E.
degrees in computer science from Tokyo Institute
of Technology, Tokyo, Japan, in 2001 and 2003,
He has been with Japan Patent Office, Tokyo,
Japan, since 2003.
Yousuke Shinnaka received the B. E. degree in
electrical and electronic engineering from Tokyo
Institute of Technology, Tokyo, Japan, in 2003. He
is currently pursuing the M.S. degree at Tokyo
Institute of Technology.
Chiori Hori (M&#8217;02) received the B.E. and M.E.
degrees in electrical and information engineering
from Yamagata University, Yonezawa, Japan, in
1994 and 1997, respectively, and the Ph.D. degree
from the Graduate School of Information Science
and Engineering, Tokyo Institute of Technology
(TITECH), Tokyo, Japan, in 2002.
From April 1997 to March 1999, she was a
Research Associate with the Faculty of Literature
and Social Sciences, Yamagata University. She is
currently a Researcher with NTT Communication
Science Laboratories (CS Labs), Nippon Telegraph and Telephone Corporation
(NTT), Kyoto, Japan, which she joined in 2002.
Dr. Hori is a member of the Acoustical Society of Japan (ASJ), the Institute
of Electronics, Information and Communication Engineers of Japan (IEICE),
and the Information Processing Society of Japan (IPSJ). She received the Paper
Award from the IEICE in 2002 for her work on speech summarization.

</biblio>

</article>
<article>
<preamble>
Gonzalez_2018_Automated_Sentence_Boundary_Detection_in_Modern_StandardArabic_Transcripts_using_Deep_Neural_Networks
</preamble>
<titre>
Available
</titre>
<auteur>
[u'Available online']
</auteur>
<abstract>
 
</abstract>
<biblio>
[1] Alotaiby, F., Foda, S., Alkharashi, I., 2010. Clitics in arabic language: a statistical study, in: 24th Pacific Asia Conference on Language,
Information and Computation.
[2] Althobaiti, M., Kruschwitz, U., Poesio, M., 2014. Aranlp: A java-based library for the processing of arabic text, in: LREC.
[3] Attia, M., Somers, H., 2008. Handling Arabic morphological and syntactic ambiguity within the LFG framework with a view to machine
translation. volume 279. University of Manchester Manchester.
[4] Bahdanau, D., Cho, K., Bengio, Y., 2014. Neural machine translation by jointly learning to align and translate. CoRR abs/1409.0473.
[5] Baldridge, J., 2005. The OpenNLP project. http://opennlp.apache.org/.
[6] Bojanowski, P., Grave, E., Joulin, A., Mikolov, T., 2016. Enriching word vectors with subword information. preprint arXiv:1607.04606 .
[7] Diab, M., 2009. Second generation amira tools for arabic processing: Fast and robust tokenization, pos tagging, and base phrase chunking, in:
2nd International Conference on Arabic Language Resources and Tools.
[8] El-Masri, M., Altrabsheh, N., Mansour, H., Ramsay, A., 2017. A web-based tool for arabic sentiment analysis. Procedia Computer Science
[9] Farghaly, A., Shaalan, K., 2009. Arabic natural language processing: Challenges and solutions. ACM Transactions on Asian Language
Information Processing (TALIP) 8, 14.
[10] Ferrucci, D., Lally, A., 2004. UIMA: An Architectural Approach to Unstructured Information Processing in the Corporate Research Environment. Natural Language Engineering 10, 327&#8211;348. doi:10.1017/S1351324904003523.
[11] Gonza&#769;lez-Gallardo, C.E., Torres-Moreno, J.M., 2018. Sentence Boundary Detection for French with Subword-Level Information Vectors and
Convolutional Neural Networks. preprint arXiv:1802.04559 .
[12] Gotoh, Y., Renals, S., 2000. Sentence boundary detection in broadcast speech transcripts, in: ASR2000-Automatic Speech Recognition:
Challenges for the new Millenium ISCA Tutorial and Research Workshop (ITRW).
[13] Habash, N., Rambow, O., Roth, R., 2009. Mada+ tokan: A toolkit for arabic tokenization, diacritization, morphological disambiguation, pos
tagging, stemming and lemmatization, in: 2nd International Conference on Arabic language resources and tools (MEDAR), Cairo, Egypt, p. 62.
[14] Habash, N.Y., 2010. Introduction to arabic natural language processing. Synthesis Lectures on Human Language Technologies 3, 1&#8211;187.
[15] Hadrich, L.B., Baccour, L., Mourad, G., 2005. Star: un syste&#768;me de segmentation de textes arabes base&#769; sur lanalyse contextuelle des signes de
ponctuations et de certaines particules, in: TALN&#8217;05.
[16] Hochreiter, S., Schmidhuber, J., 1997. Long short-term memory. Neural Computation 9, 1735&#8211;1780.
[17] Jaafar, Y., Bouzoubaa, K., 2018. A survey and comparative study of arabic nlp architectures, in: Intelligent Natural Language Processing:
Trends and Applications. Springer, pp. 585&#8211;610.
[18] Linhares Pontes, E., Huet, S., Torres-Moreno, J.M., Linhares, A.C., 2018. Cross-language text summarization using sentence and multisentence compression, in: Silberztein, M., Atigui, F., Kornyshova, E., Me&#769;tais, E., Meziane, F. (Eds.), Natural Language Processing and Information Systems, Springer International Publishing, Cham. pp. 467&#8211;479.
[19] Liu, Y., Chawla, N.V., Harper, M.P., Shriberg, E., Stolcke, A., 2006. A study in machine learning from imbalanced data for sentence boundary
detection in speech. Computer Speech &amp; Language 20, 468&#8211;494.
[20] Mallek, F., Le, N.T., Sadat, F., 2018. Automatic machine translation for arabic tweets, in: Intelligent Natural Language Processing: Trends and
Applications. Springer, pp. 101&#8211;119.
[21] Menacer, M.A., Mella, O., Fohr, D., Jouvet, D., Langlois, D., Smaili, K., 2017. An enhanced automatic speech recognition system for arabic,
in: Third Arabic Natural Language Processing Workshop, pp. 157&#8211;165.
[22] Mikolov, T., Chen, K., Corrado, G., Dean, J., 2013. Efficient estimation of word representations in vector space. preprint arXiv:1301.3781 .
[23] Pasha, A., Al-Badrashiny, M., Diab, M.T., El Kholy, A., Eskander, R., Habash, N., Pooleery, M., Rambow, O., Roth, R., 2014. Madamira: A
fast, comprehensive tool for morphological analysis and disambiguation of arabic., in: LREC, pp. 1094&#8211;1101.
[24] Pennington, J., Socher, R., Manning, C., 2014. Glove: Global vectors for word representation, in: Conference on Empirical Methods in Natural
Language Processing (EMNLP), pp. 1532&#8211;1543.
[25] Povey, D., Ghoshal, A., Boulianne, G., Burget, L., Glembek, O., Goel, N., Hannemann, M., Motlicek, P., Qian, Y., Schwarz, P., et al., 2011.
The Kaldi speech recognition toolkit, in: IEEE 2011 Workshop on Automatic Speech Recognition and Understanding, IEEE Signal Processing
[26] Silberztein, M., 2005. Nooj: a linguistic annotation system for corpus processing, in: HLT/EMNLP on Interactive Demonstrations, Association
for Computational Linguistics. pp. 10&#8211;11.
[27] Souteh, Y., Bouzoubaa, K., 2011. Safar platform and its morphological layer, in: Eleventh Conference on Language Engineering ESOLEC,
[28] Tomashenko, N., Vythelingum, K., Rousseau, A., Este&#768;ve, Y., 2016. Lium asr systems for the 2016 multi-genre broadcast arabic challenge, in:
Spoken Language Technology Workshop (SLT), 2016, IEEE. pp. 285&#8211;291.
[29] Torres-Moreno, J.M., 2014. Automatic Text Summarization. Wiley and Sons.
[30] Tran, N.T., Luong, V.T., Nguyen, N.L.T., Nghiem, M.Q., 2016. Effective attention-based neural architectures for sentence compression with
bidirectional long short-term memory, in: Seventh Symposium on Information and Communication Technology, ACM, New York, NY, USA.
pp. 123&#8211;130. URL: http://doi.acm.org/10.1145/3011077.3011111, doi:10.1145/3011077.3011111.
[31] Yu, D., Deng, L., 2016. Automatic Speech Recognition. Springer.
[32] Zribi, I., Kammoun, I., Ellouze, M., Belguith, L., Blache, P., 2016. Sentence boundary detection for transcribed tunisian arabic, in: 13th
Conference on Natural Language Processing (KONVENS 2016), pp. 323&#8211;331.

</biblio>

</article>
<article>
<preamble>
Levner_2007_Fuzzifying_clustering_algorithms_The_case_study_of_MajorClust
</preamble>
<titre>
Fuzzifying clustering algorithms:
</titre>
<auteur>
[u'The case study of MajorClust']
</auteur>
<abstract>
 Among various document clustering algorithms that have been proposed so far, the most useful are those that automatically reveal the number of clusters and assign each target document to exactly one cluster. However, in many real situations, there not exists an exact boundary between different clusters. In this work, we introduce a fuzzy version of the MajorClust algorithm. The proposed clustering method assigns documents to more than one category by taking into account a membership function for both, edges and nodes of the corresponding underlying graph. Thus, the clustering problem is formulated in terms of weighted fuzzy graphs. The fuzzy approach permits to decrease some negative effects which appear in clustering of large-sized corpora with noisy data.
</abstract>
<biblio>
1. MacKay, D.J.: Information Theory, Inference and Learning Algorithms. Cambridge
University Press (2003)
2. Mirkin, B.: Mathematical Classification and Clustering. Springer (1996)
3. MacQueen, J.B.: Some methods for classification and analysis of multivariate
observations. In: Proc. of 5-th Berkeley Symposium on Mathematical Statistics
and Probability, Berkeley, University of California Press (1967) 281&#8211;297
4. Kernighan, B., Lin, S.: An efficient heuristic procedure for partitioning graphs.
Bell Systems Technical Journal 49(2) (1970) 291&#8211;308
5. Stein, B., Nigemman, O.: On the nature of structure and its identification. Lecture
Notes in Computer Science, Springer 1665 (1999) 122&#8211;134
6. Dunn, J.C.: A fuzzy relative of the isodata process and its use in detecting compact
well-separated clusters. Journal of Cybernetics 3 (1973) 32&#8211;57
7. Bezdek, J.C.: Pattern Recognition with Fuzzy Objective Function Algoritms.
Plenum Press, New York (1981)
8. Stein, B., Busch, M.: Density-based cluster algorithms in low-dimensional and
high-dimensional applications. In: Proc. of Second International Workshop on
Text-Based Information Retrieval, TIR05. (2005) 45&#8211;56
9. Stein, B., Meyer, S.: Automatic document categorization. In: KI 2003: Advances
in Artificial Intelligence. (2003) 254&#8211;266
10. Alexandrov, M., Gelbukh, A., Rosso, P.: An approach to clustering abstracts. In:
Proc. of NLDB 2005 Conference, LNCS 3513, Springer, Verlag (2005) 275&#8211;285
11. Pinto, D., Rosso, P.: On the relative hardness of clustering corpora. In: Proc. of
TSD 2007 Conference, LNCS, Springer, Verlag (2007) To appear.
12. Neville, J., Adler, M., Jensen, D.: Clustering relational data using attribute and
link information. In: Proc. of the Text Mining and Link Analysis Workshop, IJCAI03. (2003)
13. Levner, E., Alcaide, D., Sicilia, J.: Text classification using the fuzzy borda method
and semantic grades. In: Proc. of WILF-2007 (CLIP-2007). Volume 4578 of LNAI.,
LNAI, Springer, Verlag (2007) 422&#8211;429
14. Levner, E., Alcaide, D.: Environmental risk ranking: Theory and applications for
emergency planning. Scientific Israel - Technological Advantages 8(1-2) (2006)
15. Koopmans, T., Beckman, M.: Assignment problems and the location of economic
activities. Econometrica 25 (1957) 53&#8211;76
16. Singh, S., Sharma, R.: A review of different approaches to the facility layout
problem. International Journal of Advanced Manufacutring Technology 30(5&#8211;6)
(2006) 426&#8211;433 http://dx.doi.org/10.1007/s00170-005-0087-9.
17. Klawonn, F., Ho&#776;pnner, F.: What is fuzzy about fuzzy clustering-understanding
and improving the concept of the fuzzifier. Advances in Intelligent Data Analysis
V. (2003) 254&#8211;264
18. Mamdani, E.H.: Application of fuzzy logic to approximate reasoning using linguistic synthesis. In: Proc. of the sixth international symposium on Multiple-valued
logic. (1976) 196&#8211;202
19. Zimmermann, H.: Fuzzy Sets, Decision Making and Expert Systems. Kluwer
Academic Publishers, Boston (1987)

</biblio>

</article>
<article>
<preamble>
Lin_2004_Rouge
</preamble>
<titre>
ROUGE: A Package for Automatic Evaluation of Summaries
</titre>
<auteur>
[u'Chin-Yew Lin']
</auteur>
<abstract>
 ROUGE stands for Recall-Oriented Understudy for Gisting Evaluation. It includes measures to automatically determine the quality of a summary by comparing it to other (ideal) summaries created by humans. The measures count the number of overlapping units such as n-gram, word sequences, and word pairs between the computer-generated summary to be evaluated and the ideal summaries created by humans. This paper introduces four different ROUGE measures: ROUGE-N, ROUGE-L, ROUGE-W, and ROUGE-S included in the ROUGE summarization evaluation package and their evaluatio ns. Three of them have been used in the Document Understanding Conference (DUC) 2004, a large-scale summarization evaluation sponsored by NIST. 1
</abstract>
<biblio>
. Please see Papineni et
al. (2001) for details about BLEU .
Note that the number of n-grams in the denominator of the ROUGE-N formula increases as we add
</biblio>

</article>
<article>
<preamble>
Metsis_2006_Spam_filtering_with_naive_bayes-which_naive_bayes
</preamble>
<titre>
Spam Filtering with Naive Bayes &#8211; Which Naive Bayes?
</titre>
<auteur>
[u'Vangelis Metsis']
</auteur>
<abstract>
 Naive Bayes is very popular in commercial and open-source anti-spam e-mail filters. There are, however, several forms of Naive Bayes, something the anti-spam literature does not always acknowledge. We discuss five different versions of Naive Bayes, and compare them on six new, non-encoded datasets, that contain ham messages of particular Enron users and fresh spam messages. The new datasets, which we make publicly available, are more realistic than previous comparable benchmarks, because they maintain the temporal order of the messages in the two categories, and they emulate the varying proportion of spam and ham messages that users receive over time. We adopt an experimental procedure that emulates the incremental training of personalized spam filters, and we plot roc curves that allow us to compare the different versions of nb over the entire tradeoff between true positives and true negatives.
</abstract>
<biblio>
[1] I. Androutsopoulos, J. Koutsias, K. Chandrinos, and
C. Spyropoulos. An experimental comparison of Naive
Bayesian and keyword-based anti-spam filtering with
encrypted personal e-mail messages. In 23rd ACM
SIGIR Conference, pages 160&#8211;167, Athens, Greece,
[2] I. Androutsopoulos, G. Paliouras, and E. Michelakis.
Learning to filter unsolicited commercial e-mail.
technical report 2004/2, NCSR &#8220;Demokritos&#8221;, 2004.
[3] R. Beckermann, A. McCallum, and G. Huang.
Automatic categorization of email into folders:
benchmark experiments on Enron and SRI corpora.
Technical report IR-418, University of Massachusetts
[4] X. Carreras and L. Marquez. Boosting trees for
anti-spam email filtering. In 4th International
Conference on Recent Advances in Natural Language
Processing, pages 58&#8211;64, Tzigov Chark, Bulgaria,
[5] P. Domingos and M. Pazzani. On the optimality of the
simple Bayesian classifier under zero-one loss. Machine
Learning, 29(2&#8211;3):103130, 1997.
[6] H. D. Drucker, D. Wu, and V. Vapnik. Support Vector
Machines for spam categorization. IEEE Transactions
On Neural Networks, 10(5):1048&#8211;1054, 1999.
[7] S. Eyheramendy, D. Lewis, and D. Madigan. On the
Naive Bayes model for text categorization. In 9th
International Workshop on Artificial Intelligence and
Statistics, pages 332&#8211;339, Key West, Florida, 2003.
[8] T. Fawcett. In &#8220;vivo&#8221; spam filtering: a challenge
Enron2 - Multinomial NB, Boolean - 3000 Attributes
Enron1 - Multinomial NB, Boolean - 3000 Attributes
Enron3 - Multinomial NB, Boolean - 3000 Attributes
0.95
0.95
0.95
0.9
0.9
0.9
0.85
0.85
0.85
1
0.95
0.95
0.9
0.9
0.9
0.85
0.85
0.85
Number of emails x 100
Number of emails x 100
Ham Recall
55
52
49
46
43
40
37
34
31
28
25
22
19
16
1
1
Spam Recall
0.7
0.7
0.75
Ham Recall
13
Number of emails x 100
1
Spam Recall
Ham Recall
Enron6 - Multinomial NB, Boolean - 3000 Attributes
0.95
0.8
10
Number of emails x 100
Enron5 - Multinomial NB, Boolean - 3000 Attributes
Enron4 - Multinomial NB, Boolean - 3000 Attributes

0.75


58

55

52

49

46

43

40

37

34

31

28

25

22

19

16

7

13

10 13 16 19 22 25 28 31 34 37 40 43 46 49
Number of emails x 100

10

7

4

4

1

1

Spam Recall

0.7
1

0.7

0.8

0.75

7

Ham Recall

4

Spam Recall

1

0.8
0.75

Number of emails x 100

Figure 3: Learning curves for the multinomial NB with Boolean attributes and T = 0.5.

[9]

[10]

[11]

[12]

[13]

[14]

[15]

[16]

[17]

problem for KDD. SIGKDD Explorations,
5(2):140&#8211;148, 2003.
S. Hershkop and S. Stolfo. Combining email models
for false positive reduction. In 11th ACM SIGKDD
Conference, pages 98&#8211;107, Chicago, Illinois, 2005.
J. G. Hidalgo. Evaluating cost-sensitive unsolicited
bulk email categorization. In 17th ACM Symposium
on Applied Computing, pages 615&#8211;620, 2002.
J. G. Hidalgo and M. M. Lopez. Combining text and
heuristics for cost-sensitive spam filtering. In 4th
Computational Natural Language Learning Workshop,
pages 99&#8211;102, Lisbon, Portugal, 2000.
J. Hovold. Naive Bayes spam filtering using
word-position-based attributes. In 2nd Conference on
Email and Anti-Spam, Stanford, CA, 2005.
J. T. J.D.M. Rennie, L. Shih and D. Karger. Tackling
the poor assumptions of Naive Bayes classifiers. In
20th International Conference on Machine Learning,
pages 616&#8211;623, Washington, DC, 2003.
G. John and P. Langley. Estimating continuous
distributions in Bayesian classifiers. In 11th
Conference on Uncertainty in Artificial Intelligence,
pages 338&#8211;345, Montreal, Quebec, 1995.
B. Klimt and Y. Yang. The Enron corpus: a new
dataset for email classification research. In 15th
European Conference on Machine Learning and the
8th European Conference on Principles and Practice
of Knowledge Discovery in Databases, pages 217&#8211;226,
Pisa, Italy, 2004.
A. Kolcz and J. Alspector. SVM-based filtering of
e-mail spam with content-specific misclassification
costs. In Workshop on Text Mining, IEEE
International Conference on Data Mining, San Jose,
California, 2001.
A. McCallum and K. Nigam. A comparison of event
models for naive bayes text classification. In AAAI&#8217;98
Workshop on Learning for Text Categorization, pages
41&#8211;48, Madison, Wisconsin, 1998.

[18] E. Michelakis, I. Androutsopoulos, G. Paliouras,
G. Sakkis, and P. Stamatopoulos. Filtron: a
learning-based anti-spam filter. In 1st Conference on
Email and Anti-Spam, Mountain View, CA, 2004.
[19] P. Pantel and D. Lin. SpamCop: a spam classification
and organization program. In Learning for Text
Categorization &#8211; Papers from the AAAI Workshop,
pages 95&#8211;98, Madison, Wisconsin, 1998.
[20] F. Peng, D. Schuurmans, and S. Wang. Augmenting
naive bayes classifiers with statistical language
models. Information Retrieval, 7:317&#8211;345, 2004.
[21] M. Sahami, S. Dumais, D. Heckerman, and
E. Horvitz. A Bayesian approach to filtering junk
e-mail. In Learning for Text Categorization &#8211; Papers
from the AAAI Workshop, pages 55&#8211;62, Madison,
Wisconsin, 1998.
[22] G. Sakkis, I. Androutsopoulos, G. Paliouras,
V. Karkaletsis, C. Spyropoulos, and P. Stamatopoulos.
Stacking classifiers for anti-spam filtering of e-mail. In
Conference on Empirical Methods in Natural
Language Processing, pages 44&#8211;50, Carnegie Mellon
University, Pittsburgh, PA, 2001.
[23] G. Sakkis, I. Androutsopoulos, G. Paliouras,
V. Karkaletsis, C. Spyropoulos, and P. Stamatopoulos.
A memory-based approach to anti-spam filtering for
mailing lists. Information Retrieval, 6(1):49&#8211;73, 2003.
[24] K.-M. Schneider. A comparison of event models for
Naive Bayes anti-spam e-mail filtering. In 10th
Conference of the European Chapter of the ACL,
pages 307&#8211;314, Budapest, Hungary, 2003.
[25] K.-M. Schneider. On word frequency information and
negative evidence in Naive Bayes text classification. In
4th International Conference on Advances in Natural
Language Processing, pages 474&#8211;485, Alicante, Spain,

</biblio>

</article>
<article>
<preamble>
Mikolov_2013_Distributed_representations_of_words_and_phrases_and_their_compositionality
</preamble>
<titre>
Distributed Representations of Words and Phrases
</titre>
<auteur>
[u'and their Compositionality']
</auteur>
<abstract>
 The recently introduced continuous Skip-gram model is an efficient method for learning high-quality distributed vector representations that capture a large number of precise syntactic and semantic word relationships. In this paper we present several extensions that improve both the quality of the vectors and the training speed. By subsampling of the frequent words we obtain significant speedup and also learn more regular word representations. We also describe a simple alternative to the hierarchical softmax called negative sampling. An inherent limitation of word representations is their indifference to word order and their inability to represent idiomatic phrases. For example, the meanings of &#8220;Canada&#8221; and &#8220;Air&#8221; cannot be easily combined to obtain &#8220;Air Canada&#8221;. Motivated by this example, we present a simple method for finding phrases in text, and show that learning good vector representations for millions of phrases is possible.
</abstract>
<biblio>
[1] Yoshua Bengio, Re&#769;jean Ducharme, Pascal Vincent, and Christian Janvin. A neural probabilistic language
model. The Journal of Machine Learning Research, 3:1137&#8211;1155, 2003.
[2] Ronan Collobert and Jason Weston. A unified architecture for natural language processing: deep neural networks with multitask learning. In Proceedings of the 25th international conference on Machine
learning, pages 160&#8211;167. ACM, 2008.
[3] Xavier Glorot, Antoine Bordes, and Yoshua Bengio. Domain adaptation for large-scale sentiment classification: A deep learning approach. In ICML, 513&#8211;520, 2011.
[4] Michael U Gutmann and Aapo Hyva&#776;rinen. Noise-contrastive estimation of unnormalized statistical models, with applications to natural image statistics. The Journal of Machine Learning Research, 13:307&#8211;361,
[5] Tomas Mikolov, Stefan Kombrink, Lukas Burget, Jan Cernocky, and Sanjeev Khudanpur. Extensions of
recurrent neural network language model. In Acoustics, Speech and Signal Processing (ICASSP), 2011
IEEE International Conference on, pages 5528&#8211;5531. IEEE, 2011.
[6] Tomas Mikolov, Anoop Deoras, Daniel Povey, Lukas Burget and Jan Cernocky. Strategies for Training
Large Scale Neural Network Language Models. In Proc. Automatic Speech Recognition and Understanding, 2011.
[7] Tomas Mikolov. Statistical Language Models Based on Neural Networks. PhD thesis, PhD Thesis, Brno
University of Technology, 2012.
[8] Tomas Mikolov, Kai Chen, Greg Corrado, and Jeffrey Dean. Efficient estimation of word representations
in vector space. ICLR Workshop, 2013.
[9] Tomas Mikolov, Wen-tau Yih and Geoffrey Zweig. Linguistic Regularities in Continuous Space Word
Representations. In Proceedings of NAACL HLT, 2013.
[10] Andriy Mnih and Geoffrey E Hinton. A scalable hierarchical distributed language model. Advances in
neural information processing systems, 21:1081&#8211;1088, 2009.
[11] Andriy Mnih and Yee Whye Teh. A fast and simple algorithm for training neural probabilistic language
models. arXiv preprint arXiv:1206.6426, 2012.
[12] Frederic Morin and Yoshua Bengio. Hierarchical probabilistic neural network language model. In Proceedings of the international workshop on artificial intelligence and statistics, pages 246&#8211;252, 2005.
[13] David E Rumelhart, Geoffrey E Hintont, and Ronald J Williams. Learning representations by backpropagating errors. Nature, 323(6088):533&#8211;536, 1986.
[14] Holger Schwenk. Continuous space language models. Computer Speech and Language, vol. 21, 2007.
[15] Richard Socher, Cliff C. Lin, Andrew Y. Ng, and Christopher D. Manning. Parsing natural scenes and
natural language with recursive neural networks. In Proceedings of the 26th International Conference on
Machine Learning (ICML), volume 2, 2011.
[16] Richard Socher, Brody Huval, Christopher D. Manning, and Andrew Y. Ng. Semantic Compositionality
Through Recursive Matrix-Vector Spaces. In Proceedings of the 2012 Conference on Empirical Methods
in Natural Language Processing (EMNLP), 2012.
[17] Joseph Turian, Lev Ratinov, and Yoshua Bengio. Word representations: a simple and general method for
semi-supervised learning. In Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics, pages 384&#8211;394. Association for Computational Linguistics, 2010.
[18] Peter D. Turney and Patrick Pantel. From frequency to meaning: Vector space models of semantics. In
Journal of Artificial Intelligence Research, 37:141-188, 2010.
[19] Peter D. Turney. Distributional semantics beyond words: Supervised learning of analogy and paraphrase.
In Transactions of the Association for Computational Linguistics (TACL), 353&#8211;366, 2013.
[20] Jason Weston, Samy Bengio, and Nicolas Usunier. Wsabie: Scaling up to large vocabulary image annotation. In Proceedings of the Twenty-Second international joint conference on Artificial Intelligence-Volume
Volume Three, pages 2764&#8211;2770. AAAI Press, 2011.
9

</biblio>

</article>
<article>
<preamble>
Torres-Moreno_2012_Artex_is_another_text_summarizer
</preamble>
<titre>
Artex is AnotheR TEXt summarizer
</titre>
<auteur>
[u'Juan-Manuel Torres-Moreno1,2']
</auteur>
<abstract>
 This paper describes Artex, another algorithm for Automatic Text Summarization. In order to rank sentences, a simple inner product is calculated between each sentence, a document vector (text topic) and a lexical vector (vocabulary used by a sentence). Summaries are then generated by assembling the highest ranked sentences. No ruled-based linguistic post-processing is necessary in order to obtain summaries. Tests over several datasets (coming from Document Understanding Conferences (DUC), Text Analysis Conference (TAC), evaluation campaigns, etc.) in French, English and Spanish have shown that Artex summarizer achieves interesting results.
</abstract>
<biblio>
) confirm the good
performance of Artex.
In this paper, related work is given in Section 2. Section 3 presents the new algorithm of
Automatic Text Summarization. Experiments are presented in Section 4, followed by Results
in Section 5 and Conclusions in Section 6.
Research in Automatic Text Summarization was introduced by H.P. Luhn in 1958 [9]. In the
strategy proposed by Luhn, the sentences are scored for their component word values as determined by tf*idf-like weights. Scored sentences are then ranked and selected from the top
until some summary length threshold is reached. Finally, the summary is generated by assembling the selected sentences in the original source order. Although fairly simple, this extractive
methodology is still used in current approaches. Later on, [3] extended this work by adding simple heuristic features such as the position of sentences in the text or some key phrases indicate
the importance of the sentences. As the range of possible features for source characterization
widened, choosing appropriate features, feature weights and feature combinations have become
a central issue.
A natural way to tackle this problem is to consider sentence extraction as a classification
task. To this end, several machine learning approaches that uses document-summary pairs
have been proposed [6, 12], An hybrid method mixing statistical and linguistics algorithms is
presented in [1]. [10] and [15] propose a good state-of-art of Automatic Text Summarization
tasks and algorithms.
2.1
Document Pre-processing
The first step to represent documents in a suitable space is the pre-processing. As we use
extractive summarization, documents have to be chunked into cohesive textual segments that
will be assembled to produce the summary. Pre-processing is very important because the
selection of segments is based on words or bigrams of words. The choice was made to split
documents into full sentences, in this way obtaining textual segments that are likely to be
grammatically corrects. Afterwards, sentences pass through several basic normalization steps
in order to reduce computational complexity.
The process is composed by the following steps:
1. Sentence splitting. Simple rule-based method is used for sentence splitting. Documents
are chunked at the period, exclamation and question mark.
2. Sentence filtering. Words lowercased and cleared up from sloppy punctuation. Words
with less than 2 occurrences (f &lt; 2) are eliminated (Hapax legomenon presents once in a
document). Words that do not carry meaning such as functional or very common words
are removed. Small stop-lists (depending of language) are used in this step.
3. Word normalization. Remaining words are replaced by their canonical form using
lemmatization, stemming, ultra-stemming or none of them (raw text). Four methods of
normalization were applied after filtering:
&#8226; Lemmatization by simples dictionaries of morphological families. These dictionaries
have 1.32M, 208K and 316K words-entries in Spanish, English and French, respectively.
&#8226; Porter&#8217;s Stemming, available at Snowball (web site http://snowball.tartarus.
org/texts/stemmersoverview.html) for English, Spanish, French among other languages.
&#8226; Ultra-stemming. This normalization seems be very efficient and it produces a compact matrix representation [16]. Ultra-stemming consider only the n first letters of
each word. For example, in the case of ultra-stemming (first letter, Fix1 ), inflected
verbs like &#8220;sing&#8221;, &#8220;song&#8221;, &#8220;sings&#8221;, &#8220;singing&#8221;... or proper names &#8220;smith&#8221;, &#8220;snowboard&#8221;,
&#8220;sex&#8221;,... are replaced by the letter &#8220;s&#8221;.
4. Text Vectorization. Documents are vectorized in a matrix S[P &#215;N ] of P sentences and
N columns. Each element si,j represents the occurrences of an object j (a letter in the
case of ultra-stemming, a word in the case of lemmatization or a stem for stemming),
j = 1, 2, ..., N in the sentence i, i = 1, 2, ..., P .
3
AnotheR TEXt summarizer (Artex)
Artex1 is a simple extractive algorithm for Automatic Text Summarization. The main idea is
the next one: First, we represent the text in a suitable space model (VSM). Then, we construct
an average document vector that represents the average (the &#8220;global topic&#8221;) of all sentences
vectors. At the same time, we obtain the &#8220;lexical weight&#8221; for each sentence, i.e. the number of
words in the sentence. After that, it is calculated the angle between the average document and
each sentence; narrow angles indicate that the sentences near of the &#8220;global topic&#8221; should be
important and therefore extracted. See on the figure 1 the VSM of words: P vector sentences
and the average &#8220;global topic&#8221; are represented in a N dimensional space of words.
w1
VSM words
s1
b Global topic
s2
wj
sP
Angle cos &#945;=(b &#8226; s )/||b|| ||s ||
Figure 1: The &#8220;global topic&#8221; in a Vector Space Model of N words.
Next, a score for each sentence is calculated using their proximity with the &#8220;global topic&#8221;
and their &#8220;lexical weight&#8221;. In the figure 2, the &#8220;lexical weight&#8221; is represented in a VSM of P
Finally, the summary is generated concatenating the sentences with the highest scores following their order in the original document.
French, Artex est un Autre R&#233;sumeur TEXtuel.
VSM sentences
w1
s1
a Lexical weight
wj
sP
wN
Figure 2: The &#8220;lexical weight&#8221; in a Vector Space Model of P sentences.
3.1
Algorithm
Formally, Artex algorithm computes the score of each sentence by calculating the inner product
between a sentence vector, an average pseudo-sentence vector (the &#8220;global topic&#8221;) and an average
pseudo-word vector (the &#8220;lexical weight&#8221;).
Once a pre-processing (word normalization and filtering of stop words) is completed, it is
created a matrix S[P &#215;N ] , using the Vector Space Model, that contains N words (or letters) and
Let si = (s1 , s2 , ..., sN ) be a vector of the sentence i, i = 1, 2, ..., P . We defined ~a the average
pseudo-word vector, as the average number of occurrences of N words used in the sentence i:
si,j
and ~b the average pseudo-sentence vector as the average number of occurrences of each word j
used trough the P sentences:
si,j
The score or weight of each sentence si is calculated as follows:
(3)

score(si ) = ~s &#215; ~b &#215; ~a =
si,j &#215; bj &#63736; &#215; ai ; i = 1, 2, ..., P ; j = 1, 1, ..., N
j
The score(&#8226;) computed by equation 3 must be normalized between the interval [0,1]. The
calculation of ~s &#215; ~b indicates the proximity between the sentence ~s and the average pseudosentence ~b. The product (~s &#215; ~b) &#215; ~a weigh this proximity using the average pseudo-word ai .
If a sentence si is near of ~b and their corresponding element ai has a high value, si will have,
therefore, a high score. Moreover, a sentence i far of main topic (i.e. ~si &#215; ~b is near 0) or a less
informative sentence i (i.e. ai are near 0) will have a low score.
In computational terms, it is not really necessary to divide the scalar product by the constant
~ s/|~b||~s| between ~b and ~s is the same if we use ~b = ~b0 = P si,j .
N P , because the angle &#945; = arccos b.~
The element ai is only a scale factor that does not modify &#945;.
In fact, if the matrix S[P &#215;N ] is approximated to a binary matrix2 S[P
&#215;N ] , where each element
s0 = {0, 1} has a probability of p = , we can normalize vectors ~a, ~b and matrix S, as follows:
|~b| =
(5)
s0i,j 2 =
|~si | =
j
N q
NP
j
j
(6)

&#8730;
({0, 1}P )2 = N P

i

i
N q

P q
X

s0i,j 2 =

X

{0, 1}2 = N

j

Vectors then will be represented in hyper-spheres of N or P dimensions, and the normalized
score&#8217; in this space would be:

score&#8217;(si )

(7)

=

=

&#63723;
!
X
~b
~s
&#8730; &#63725;
si,j &#215; bj &#63736; &#215; ai
= &#8730;
|~a|
j
&#63723;
&#63734;
X
1
&#63725;
&#8730;
si,j &#215; bj &#63736; &#215; ai ; i = 1, 2, ..., P ; j = 1, 2, ..., N
j

&#8730;
However, the term 1/ N 5 P 3 is a constant value (i.e. a simple scale factor), and then the
score(&#8226;) calculated using the equation 3) and the score&#8217;(&#8226;) using the equation 7, are both



Artex algorithm described in the previous section has been implemented and evaluated in
corpora in several languages.
We have conducted our experimentation with the following languages, summarization tasks,
summarizers and data sets: 1) Generic multi-document-summarization in English with the
corpus DUC&#8217;04; 2) Generic single-document summarization in Spanish with the corpus Medicina
Cl&#237;nica and 3) Generic single document summarization in French with the corpus Pistes.
We have applied the summarization algorithms and finally, the results have been evaluated
using Fresa while processing times for each summarizer have been measured and compared.
The following subsections present formally the details of the summarizers, corpora and
evaluations studied in different experiments.
2 This is a reasonable approximation in this context, because S
[P &#215;N ] is a sparsed matrix with many term
occurrences equal to one or zero.

4.1

Other Summarizers

To compare the performances, two other summarization systems were used in our experiments:
Cortex and Enertex. To be in the same conditions, these two systems have used exactly the
same textual representation based on Vector Space Model, described in Section 2.1.
&#8226; Cortex is a single-document summarization system using several metrics and an optimal
decision algorithm [4, 14, 15, 18].
&#8226; Enertex is a summarization system based in Textual Energy concept [5]: text is represented as a spin system where spins &#8593; represents words that their occurrences are f &gt; 1
(spins &#8595; if the word is not present).

4.2

Summarization Corpora Description

To study the impact of our summarizer, we used corpora in three languages: English, Spanish
and French. The corpora are heterogeneous, and different tasks are representatives of Automatic Text Summarization: generic multi-document summary and mono-document guided by
&#8226; Corpus in English. Piloted by NIST in Document Understanding Conference3 (DUC) the
Task 2 of DUC&#8217;044 , aims to produce a short summary of a cluster of related documents.
We studied generic multi-document-summarization in English using data from DUC&#8217;04.
This corpus with 300K words (17 780 types) is compound of 50 clusters, 10 documents
&#8226; Corpus in Spanish. Generic single-document summarization using a corpus from the
scientific journal Medicina Cl&#237;nica5 , which is composed of 50 medical articles in Spanish,
each one with its corresponding author abstract. This corpus contains 125K words (9 657
&#8226; Corpus in French. We have studied generic single-document summarization using the
Canadian French Sociological Articles corpus, generated from the journal Perspectives
interdisciplinaires sur le travail et la sant&#233; (Pistes)6 . It contains 50 sociological articles
in French, each one with its corresponding author abstract. This corpus contains near
400K words (18 887 types).

4.3

Summaries Content Evaluation

DUC conferences have introduced the ROUGE content evaluation [7], wich measures the overlap of n-grams between a candidate summary and reference summaries written by humans.
However, to write the human summaries necessaries for ROUGE is a very expensive task.
Recently metrics without 
</biblio>

</article>
<article>
<preamble>
Vanderwende_2007_Beyond_SumBasic
</preamble>
<titre>
Information Processing and Management 43 (2007) 1606&#8211;1618
</titre>
<auteur>
[u'www.elsevier.com/locate/infoproman']
</auteur>
<abstract>
 In recent years, there has been increased interest in topic-focused multi-document summarization. In this task, automatic summaries are produced in response to a speci&#64257;c information request, or topic, stated by the user. The system we have designed to accomplish this task comprises four main components: a generic extractive summarization system, a topic-focusing component, sentence simpli&#64257;cation, and lexical expansion of topic words. This paper details each of these components, together with experiments designed to quantify their individual contributions. We include an analysis of our results on two large datasets commonly used to evaluate task-focused summarization, the DUC2005 and DUC2006 datasets, using automatic metrics. Additionally, we include an analysis of our results on the DUC2006 task according to human evaluation metrics. In the human evaluation of system summaries compared to human summaries, i.e., the Pyramid method, our system ranked &#64257;rst out of 22 systems in terms of overall mean Pyramid score; and in the human evaluation of summary responsiveness to the topic, our system ranked third out of 35 systems. &#211; 2007 Elsevier Ltd. All rights reserved. 
</abstract>
<biblio>
Brockett, C., &amp; Dolan, W. B. (2005). Support vector machines for paraphrase identi&#64257;cation and corpus construction. In Proceedings of the
third international workshop on paraphrasing (IWP2005), Jeju, Republic of Korea.
Conroy, J. M., Schlesinger, J., &amp; Goldstein Stewart, J. (2005). CLASSY query-based multi-document summarization. In Proceedings of
Daume&#769;, H., III, &amp; Marcu, D. (2005a). Bayesian multi-document summarization at MSE. In Proceedings of MSE 2005.
Daume&#769;, H., III, &amp; Marcu, E. (2005b). Bayesian summarization at DUC and a suggestion for extrinsice evaluation. In Proceedings of DUC
Dolan, W. B., Quirk, C., &amp; Brockett, C. (2004). Unsupervised construction of large paraphrase corpora: exploiting massively parallel news
sources. In Proceedings of COLING 2004, Geneva, Switzerland.
Dorr, B., Zajic, D., &amp; Schwartz, R. (2003). Hedge trimmer: a parse-and-trim approach to headline generation. In Proceedings of HLTNAACL 2003 text summarization workshop (pp. 1&#8211;8).
Dunlavy, D., Conroy, J., Schlesinger, J., Goodman, S., Okurowski, M., O&#8217;Leary, E., et al. (2003). Performance of a three-stage system for
multi-document summarization. In Proceedings of DUC 2003.
Fellbaum, C. (Ed.). (1998). WordNet: An electronic lexical database. The MIT Press.
Jing, H., &amp; McKeown, K. (2000). Cut and past based text summarization. In Proceedings of the 1st conference of the North American
Chapter of the Association for Computational Linguistics (NAACL&#8217;00).
Lin, C. Y. (2004). ROUGE: a package for automatic evaluation of summaries. In Proceedings of the workshop on text summarization
branches out, 25&#8211;26 July 2004, Barcelona, Spain.
Luhn, H. P. (1958). The automatic creation of literature abstracts. IBM Journal of Research and Development, 2(2), 159&#8211;165.
Mitra, M., Singhal, A., &amp; Buckley, C. (1998). Improving automatic query expansion. In Proceedings of the 21st Annual International ACMSIGIR conference on research and development in information retrieval.
Moore, R. C. (2001). Towards a simple and accurate statistical approach to learning translation relationships among words. In
Proceedings, workshop on data-driven machine translation, Toulouse, France.
Moore, R. C. (2004). Association-based bilingual word alignment. In Proceedings, workshop on building and using parallel texts: datadriven machine translation and beyond, Ann Arbor, MI.
Nenkova, A., &amp; Vanderwende, L. (2005). The impact of frequency on summarization. MSR-TR-2005-101.
Nenkova, A., Vanderwende, L., &amp; McKeown, K. (2006). A compositional context sensitive multidocument summarizer. In Proceedings of
Nenkova, A., &amp; Passonneau, R. (2004). Evaluating content selection in summarization: the Pyramid method. In Proceedings of the HLTNAACL 2004.
Och, F. J., &amp; Ney, H. (2003). A systematic comparison of various statistical alignment models. Computational Linguistics, 29(1), 19&#8211;52.
Quirk, C., Brockett, C., &amp; Dolan, W. B. (2004). Monolingual machine translation for paraphrase generation. In Proceedings of the 2004
conference on empirical methods in natural language processing, 25&#8211;26 July 2004, Barcelona Spain (pp. 142&#8211;149).
Ringger, E., Moore, R. C., Charniak, E., Vanderwende, L., &amp; Suzuki, H. (2004). Using the Penn treebank to evaluate non-treebank
parsers. In Proceedings of LREC 2004.
Rooney, K. (2001). Encarta Thesaurus. Bloomsbury Publishing.
1618
L. Vanderwende et al. / Information Processing and Management 43 (2007) 1606&#8211;1618
Siddharthan, A., Nenkova, A., &amp; McKeown, K. (2004). Syntactic simpli&#64257;cation for improving content selection in multi-document
summarization. In Proceedings of COLING 2004.
Voorhees, E. (1988). Using WordNet for text retrieval. In C. Fellbaum (Ed.), WordNet: An electronic lexical database. The MIT Press.
Zajic, D., Dorr, B., Lin, J., Monz, C., &amp; Schwartz, R. (2005). A sentence-trimming approach to multi-document summarization. In
Proceedings of DUC2005.

</biblio>

</article>
